[write]
  concurrency = 10
  batch_size = 5000
  batch_interval = "0s"
  database = "stress"
  precision = "1s"
  address = "localhost:8086"
  reset_database = true
  starting_point = "6m" # how far back in time to go

## Fine grained control over what series gets written
[[series]]
  point_count = 100 # number of points that will be written for each of the series
  measurement = "cpu"
  # series count
  generic_tagset_cardinality = 100000 # defaults to 0. needs to be power of 10.

  [[series.tag]]
    key = "host"
    values = ["idk", "wtf"]

  [[series.tag]]
    key = "location"
    values = ["lame", "ness"]

  [[series.field]]
    key = "value"
    type = "float64"

  [[series.field]]
    key = "loc"
    type = "bool"

 ## Generate large number of series with a generic tags
 [[series]]
   point_count = 100
   measurement = "mem"
   # series count
   generic_tagset_cardinality = 100000 # defaults to 0. needs to be power of 10.

   [[series.field]]
     key = "value"
     type = "float64"

 ## Combined specific and generic
 [[series]]
   point_count = 100 # number of points that will be written for each of the series
   measurement = "dog"
   generic_tagset_cardinality = 100000 # defaults to 0. needs to be a power of 10.
   [[series.tag]]
     key = "host"
     values = ["idk", "wtf"]

   [[series.tag]]
     key = "location"
     values = ["lame", "ness"]

   [[series.field]]
     key = "value"
     type = "float64"

   [[series.field]]
     key = "loc"
     type = "bool"


[[query]]
  concurrency = 10
  measurement = "cpu"
  tag_key = "host"
  time_frame = "5m" # defaults to 0 which will query over all time
  statement = "SELECT count(value) FROM #{measurement} WHERE #{tag_key}=#{tag_value}" # needs work

[[query]]
  concurrency = 1
  statement = "SELECT count(value) FROM cpu" # needs work

